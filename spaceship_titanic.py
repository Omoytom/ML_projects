# -*- coding: utf-8 -*-
"""Spaceship_Titanic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XZdv1cmQ0KBDfjczEKdwU9QYjFH7QQDe
"""

!unzip spaceship-titanic\ \(1\).zip

"""**Preparing the** **Tools**"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# we want our plots to appear inside the notebook
# %matplotlib inline

# Models from Scikit-Learn
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

# Model Evaluations
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import precision_score, recall_score, f1_score

"""**Loading** **data**"""

df = pd.read_csv("/content/train.csv")
df

df.shape

"""**Exploratory Data Analysis**"""

df.head()

df.tail()

df["Transported"].value_counts()

df["Transported"].value_counts().plot(kind="bar", color=["yellow", "blue"]);

df.info()

df.isna().sum()

df.describe()

df.CryoSleep.value_counts()

pd.crosstab(df.Transported, df.CryoSleep)

df["Age"].value_counts()

df.Age.plot.hist()

pd.crosstab(df.Transported, df.Age)

"""**Modelling**"""

X = df.drop("Transported", axis=1)

y = df["Transported"]

np.random.seed(42)
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)

len(X_train)

s = (X_train.dtypes == 'object')
object_cols = list(s[s].index)

from sklearn.preprocessing import OneHotEncoder

# Apply one-hot encoder to each column with categorical data
OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))
OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[object_cols]))

# One-hot encoding removed index; put it back
OH_cols_train.index = X_train.index
OH_cols_test.index = X_test.index

# Remove categorical columns (will replace with one-hot encoding)
num_X_train = X_train.drop(object_cols, axis=1)
num_X_test = X_test.drop(object_cols, axis=1)

# Add one-hot encoded columns to numerical features
OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)
OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)

# Ensure all columns have string type
OH_X_train.columns = OH_X_train.columns.astype(str)
OH_X_test.columns = OH_X_test.columns.astype(str)

from sklearn.impute import SimpleImputer

# Imputation
my_imputer = SimpleImputer()
imputed_X_train = pd.DataFrame(my_imputer.fit_transform(OH_X_train))
imputed_X_test = pd.DataFrame(my_imputer.transform(OH_X_test))

# Imputation removed column names; put them back
imputed_X_train.columns = OH_X_train.columns
imputed_X_test.columns = OH_X_test.columns

from xgboost import XGBClassifier
models = {"Logistic Regression": LogisticRegression(),
          "XG Boost" : XGBClassifier(),
          "Random Forest": RandomForestClassifier()}
def fit_and_score(models, X_train, X_test, y_train, y_test):
    """
    Fits and evaluates given machine learning models.
    models : a dict of different Scikit-Learn machine learning models
    X_train : training data (no labels)
    X_test : testing data (no labels)
    y_train : training labels
    y_test : test labels
    """
    # Set Random seed
    np.random.seed(42)
    # Make a dictionary to keep model scores
    model_scores = {}
    # Loop through models
    for name, model in models.items():
        # Fit the model to the data
        model.fit(X_train, y_train)
        # Evaluate the model and append its score to model_scores
        model_scores[name] = model.score(X_test, y_test)
    return model_scores

model_scores = fit_and_score(models=models,
                             X_train=imputed_X_train,
                             X_test=imputed_X_test,
                             y_train=y_train,
                             y_test=y_test)

model_scores

model_Xgb = XGBClassifier()
bst = model_Xgb.fit(imputed_X_train, y_train)

y_pred_prob = model_Xgb.predict(imputed_X_test)
y_pred = [True if prob > 0.5 else False for prob in y_pred_prob]

from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

import xgboost as xgb
test_df = pd.read_csv("/content/test.csv")
s = (test_df.dtypes == 'object')
categorical_columns = list(s[s].index)
X_new_encoded = pd.get_dummies(test_df, columns=categorical_columns)
X_new_encoded = X_new_encoded.reindex(columns=imputed_X_train.columns, fill_value=0)

print(X_train.dtypes)
print(X_new_encoded.dtypes)

X_new_encoded = pd.DataFrame(X_new_encoded)
dnew = xgb.DMatrix(X_new_encoded)
predictions_prob = bst.predict(X_new_encoded)
predictions = [True if prob > 0.5 else False for prob in predictions_prob]

test_df['Transported'] = predictions

print(test_df[['PassengerId', 'Transported']])

data = test_df[['PassengerId', 'Transported']]
data.to_csv('submission_file.csv', index=False)

